import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
try:
    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.svm import SVC, SVR
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score, f1_score, 
        mean_squared_error, r2_score, classification_report, confusion_matrix
    )
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.decomposition import PCA
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    st.error("scikit-learnã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ©Ÿæ¢°å­¦ç¿’æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
import joblib
import io
import base64
from datetime import datetime

st.set_page_config(
    page_title="æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ³ãƒ",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ³ãƒ")

# ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
@st.cache_data
def generate_ml_data():
    """æ©Ÿæ¢°å­¦ç¿’ç”¨ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # åˆ†é¡å•é¡Œç”¨ãƒ‡ãƒ¼ã‚¿
    n_samples = 1000
    
    # ç‰¹å¾´é‡
    feature1 = np.random.normal(0, 1, n_samples)
    feature2 = np.random.normal(0, 1, n_samples)
    feature3 = np.random.normal(0, 1, n_samples)
    feature4 = np.random.normal(0, 1, n_samples)
    feature5 = np.random.normal(0, 1, n_samples)
    
    # åˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆ2ã‚¯ãƒ©ã‚¹ï¼‰
    # éç·šå½¢ãªæ±ºå®šå¢ƒç•Œã‚’ä½œæˆ
    target_classification = ((feature1**2 + feature2**2 > 2) & 
                           (feature3 > 0) & 
                           (feature4 + feature5 > 0)).astype(int)
    
    # å›å¸°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    target_regression = (2 * feature1 + 3 * feature2 - 1.5 * feature3 + 
                        0.5 * feature4 + 1.2 * feature5 + np.random.normal(0, 0.5, n_samples))
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿
    cluster_data = np.column_stack([
        np.random.normal(0, 1, n_samples),
        np.random.normal(0, 1, n_samples),
        np.random.normal(0, 1, n_samples)
    ])
    
    # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡
    categories = np.random.choice(['A', 'B', 'C'], n_samples)
    
    return {
        'classification': pd.DataFrame({
            'feature1': feature1,
            'feature2': feature2,
            'feature3': feature3,
            'feature4': feature4,
            'feature5': feature5,
            'category': categories,
            'target': target_classification
        }),
        'regression': pd.DataFrame({
            'feature1': feature1,
            'feature2': feature2,
            'feature3': feature3,
            'feature4': feature4,
            'feature5': feature5,
            'category': categories,
            'target': target_regression
        }),
        'clustering': pd.DataFrame({
            'feature1': cluster_data[:, 0],
            'feature2': cluster_data[:, 1],
            'feature3': cluster_data[:, 2]
        })
    }

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
data = generate_ml_data()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - ã‚¿ã‚¹ã‚¯é¸æŠ
st.sidebar.title("ğŸ¯ æ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯")

if not SKLEARN_AVAILABLE:
    st.error("âš ï¸ scikit-learnãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ©Ÿæ¢°å­¦ç¿’æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")
    st.stop()

task = st.sidebar.selectbox(
    "ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ",
    ["åˆ†é¡å•é¡Œ", "å›å¸°å•é¡Œ", "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°", "ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"]
)

if task == "åˆ†é¡å•é¡Œ":
    st.subheader("ğŸ” åˆ†é¡å•é¡Œ")
    
    df = data['classification']
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ã‚µãƒ³ãƒ—ãƒ«æ•°", len(df))
    with col2:
        st.metric("ç‰¹å¾´é‡æ•°", len(df.columns) - 1)
    with col3:
        st.metric("ã‚¯ãƒ©ã‚¹æ•°", df['target'].nunique())
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ
    col1, col2 = st.columns(2)
    
    with col1:
        target_counts = df['target'].value_counts()
        fig_target = px.pie(
            values=target_counts.values,
            names=target_counts.index,
            title="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ"
        )
        st.plotly_chart(fig_target, use_container_width=True)
    
    with col2:
        # ç‰¹å¾´é‡ã®åˆ†å¸ƒ
        selected_feature = st.selectbox("ç‰¹å¾´é‡ã‚’é¸æŠ", ['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])
        
        fig_dist = px.histogram(
            df,
            x=selected_feature,
            color='target',
            title=f"{selected_feature}ã®åˆ†å¸ƒï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ï¼‰",
            barmode='overlay'
        )
        st.plotly_chart(fig_dist, use_container_width=True)
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    
    model_type = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        ["ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°", "SVM"]
    )
    
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    st.subheader("âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    
    if model_type == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
        n_estimators = st.slider("n_estimators", 10, 200, 100)
        max_depth = st.slider("max_depth", 3, 20, 10)
        min_samples_split = st.slider("min_samples_split", 2, 20, 2)
        
        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            random_state=42
        )
    
    elif model_type == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
        C = st.slider("C (æ­£å‰‡åŒ–å¼·åº¦)", 0.1, 10.0, 1.0)
        max_iter = st.slider("max_iter", 100, 1000, 100)
        
        model = LogisticRegression(C=C, max_iter=max_iter, random_state=42)
    
    else:  # SVM
        C = st.slider("C (æ­£å‰‡åŒ–å¼·åº¦)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("kernel", ['rbf', 'linear', 'poly'])
        
        model = SVC(C=C, kernel=kernel, random_state=42)
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    if 'category' in df.columns:
        le = LabelEncoder()
        df['category_encoded'] = le.fit_transform(df['category'])
        features = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'category_encoded']
    else:
        features = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']
    
    X = df[features]
    y = df['target']
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.5, 0.2)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    use_scaling = st.checkbox("ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°", value=True)
    if use_scaling:
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        X_train_final = X_train_scaled
        X_test_final = X_test_scaled
    else:
        X_train_final = X_train
        X_test_final = X_test
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"):
        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­..."):
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model.fit(X_train_final, y_train)
            
            # äºˆæ¸¬
            y_pred = model.predict(X_test_final)
            y_pred_proba = model.predict_proba(X_test_final)[:, 1] if hasattr(model, 'predict_proba') else None
            
            # è©•ä¾¡æŒ‡æ¨™
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            
            # çµæœè¡¨ç¤º
            st.subheader("ğŸ“Š è©•ä¾¡çµæœ")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ­£è§£ç‡", f"{accuracy:.3f}")
            with col2:
                st.metric("é©åˆç‡", f"{precision:.3f}")
            with col3:
                st.metric("å†ç¾ç‡", f"{recall:.3f}")
            with col4:
                st.metric("F1ã‚¹ã‚³ã‚¢", f"{f1:.3f}")
            
            # æ··åŒè¡Œåˆ—
            st.subheader("ğŸ“ˆ æ··åŒè¡Œåˆ—")
            cm = confusion_matrix(y_test, y_pred)
            
            fig_cm = px.imshow(
                cm,
                text_auto=True,
                aspect="auto",
                title="æ··åŒè¡Œåˆ—",
                labels=dict(x="äºˆæ¸¬", y="å®Ÿéš›")
            )
            st.plotly_chart(fig_cm, use_container_width=True)
            
            # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
            st.subheader("ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df, use_container_width=True)
            
            # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®å ´åˆï¼‰
            if hasattr(model, 'feature_importances_'):
                st.subheader("ğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦")
                
                importance_df = pd.DataFrame({
                    'feature': features,
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=True)
                
                fig_importance = px.barh(
                    importance_df,
                    x='importance',
                    y='feature',
                    title="ç‰¹å¾´é‡é‡è¦åº¦"
                )
                st.plotly_chart(fig_importance, use_container_width=True)
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            st.subheader("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
            if st.button("ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"):
                model_filename = f"classification_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                joblib.dump(model, model_filename)
                st.success(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {model_filename} ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ")

elif task == "å›å¸°å•é¡Œ":
    st.subheader("ğŸ“ˆ å›å¸°å•é¡Œ")
    
    df = data['regression']
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ã‚µãƒ³ãƒ—ãƒ«æ•°", len(df))
    with col2:
        st.metric("ç‰¹å¾´é‡æ•°", len(df.columns) - 1)
    with col3:
        st.metric("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç¯„å›²", f"{df['target'].min():.2f} - {df['target'].max():.2f}")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ
    col1, col2 = st.columns(2)
    
    with col1:
        fig_target = px.histogram(
            df,
            x='target',
            title="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ"
        )
        st.plotly_chart(fig_target, use_container_width=True)
    
    with col2:
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚
        selected_feature = st.selectbox("ç‰¹å¾´é‡ã‚’é¸æŠ", ['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])
        
        fig_scatter = px.scatter(
            df,
            x=selected_feature,
            y='target',
            title=f"{selected_feature} vs ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ"
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    
    model_type = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        ["ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ", "ç·šå½¢å›å¸°", "SVR"]
    )
    
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    st.subheader("âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    
    if model_type == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ":
        n_estimators = st.slider("n_estimators", 10, 200, 100)
        max_depth = st.slider("max_depth", 3, 20, 10)
        
        model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42
        )
    
    elif model_type == "ç·šå½¢å›å¸°":
        model = LinearRegression()
    
    else:  # SVR
        C = st.slider("C (æ­£å‰‡åŒ–å¼·åº¦)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("kernel", ['rbf', 'linear', 'poly'])
        
        model = SVR(C=C, kernel=kernel)
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    if 'category' in df.columns:
        le = LabelEncoder()
        df['category_encoded'] = le.fit_transform(df['category'])
        features = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'category_encoded']
    else:
        features = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']
    
    X = df[features]
    y = df['target']
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.5, 0.2)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    use_scaling = st.checkbox("ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°", value=True)
    if use_scaling:
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        X_train_final = X_train_scaled
        X_test_final = X_test_scaled
    else:
        X_train_final = X_train
        X_test_final = X_test
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"):
        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­..."):
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model.fit(X_train_final, y_train)
            
            # äºˆæ¸¬
            y_pred = model.predict(X_test_final)
            
            # è©•ä¾¡æŒ‡æ¨™
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            r2 = r2_score(y_test, y_pred)
            
            # çµæœè¡¨ç¤º
            st.subheader("ğŸ“Š è©•ä¾¡çµæœ")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("MSE", f"{mse:.3f}")
            with col2:
                st.metric("RMSE", f"{rmse:.3f}")
            with col3:
                st.metric("RÂ²", f"{r2:.3f}")
            
            # äºˆæ¸¬ vs å®Ÿéš›
            st.subheader("ğŸ“ˆ äºˆæ¸¬ vs å®Ÿéš›")
            
            fig_pred = px.scatter(
                x=y_test,
                y=y_pred,
                title="äºˆæ¸¬ vs å®Ÿéš›ã®å€¤",
                labels={'x': 'å®Ÿéš›ã®å€¤', 'y': 'äºˆæ¸¬å€¤'}
            )
            fig_pred.add_trace(go.Scatter(
                x=[y_test.min(), y_test.max()], 
                y=[y_test.min(), y_test.max()], 
                mode='lines', 
                name='å®Œå…¨äºˆæ¸¬',
                line=dict(dash='dash')
            ))
            st.plotly_chart(fig_pred, use_container_width=True)
            
            # æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
            residuals = y_test - y_pred
            
            fig_residual = px.scatter(
                x=y_pred,
                y=residuals,
                title="æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ",
                labels={'x': 'äºˆæ¸¬å€¤', 'y': 'æ®‹å·®'}
            )
            fig_residual.add_hline(y=0, line_dash="dash", line_color="red")
            st.plotly_chart(fig_residual, use_container_width=True)
            
            # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®å ´åˆï¼‰
            if hasattr(model, 'feature_importances_'):
                st.subheader("ğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦")
                
                importance_df = pd.DataFrame({
                    'feature': features,
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=True)
                
                fig_importance = px.barh(
                    importance_df,
                    x='importance',
                    y='feature',
                    title="ç‰¹å¾´é‡é‡è¦åº¦"
                )
                st.plotly_chart(fig_importance, use_container_width=True)

elif task == "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°":
    st.subheader("ğŸ¯ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
    
    df = data['clustering']
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ã‚µãƒ³ãƒ—ãƒ«æ•°", len(df))
    with col2:
        st.metric("ç‰¹å¾´é‡æ•°", len(df.columns))
    with col3:
        st.metric("ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ", len(df.columns))
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
    st.subheader("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig_scatter = px.scatter(
            df,
            x='feature1',
            y='feature2',
            title="Feature1 vs Feature2"
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    with col2:
        fig_3d = px.scatter_3d(
            df,
            x='feature1',
            y='feature2',
            z='feature3',
            title="3Dæ•£å¸ƒå›³"
        )
        st.plotly_chart(fig_3d, use_container_width=True)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
    st.subheader("ğŸ¤– ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")
    
    n_clusters = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", 2, 10, 3)
    
    # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    if st.button("ğŸš€ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ"):
        with st.spinner("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¸­..."):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            df['cluster'] = kmeans.fit_predict(df)
            
            # çµæœè¡¨ç¤º
            st.subheader("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ")
            
            # ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ
            cluster_counts = df['cluster'].value_counts().sort_index()
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig_cluster_dist = px.bar(
                    x=cluster_counts.index,
                    y=cluster_counts.values,
                    title="ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ"
                )
                st.plotly_chart(fig_cluster_dist, use_container_width=True)
            
            with col2:
                fig_cluster_scatter = px.scatter(
                    df,
                    x='feature1',
                    y='feature2',
                    color='cluster',
                    title="ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆ2Dï¼‰"
                )
                st.plotly_chart(fig_cluster_scatter, use_container_width=True)
            
            # 3Dã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
            fig_cluster_3d = px.scatter_3d(
                df,
                x='feature1',
                y='feature2',
                z='feature3',
                color='cluster',
                title="ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆ3Dï¼‰"
            )
            st.plotly_chart(fig_cluster_3d, use_container_width=True)
            
            # ã‚¯ãƒ©ã‚¹ã‚¿çµ±è¨ˆ
            st.subheader("ğŸ“‹ ã‚¯ãƒ©ã‚¹ã‚¿çµ±è¨ˆ")
            cluster_stats = df.groupby('cluster').agg(['mean', 'std']).round(3)
            st.dataframe(cluster_stats, use_container_width=True)

elif task == "ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°":
    st.subheader("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    
    df = data['classification'].copy()
    
    st.subheader("ğŸ“‹ å…ƒãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•
    st.subheader("ğŸ› ï¸ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•")
    
    # å¤šé …å¼ç‰¹å¾´é‡
    if st.checkbox("å¤šé …å¼ç‰¹å¾´é‡ã‚’è¿½åŠ "):
        df['feature1_squared'] = df['feature1'] ** 2
        df['feature2_squared'] = df['feature2'] ** 2
        df['feature1_feature2'] = df['feature1'] * df['feature2']
        st.success("å¤šé …å¼ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    # çµ±è¨ˆç‰¹å¾´é‡
    if st.checkbox("çµ±è¨ˆç‰¹å¾´é‡ã‚’è¿½åŠ "):
        df['feature_mean'] = df[['feature1', 'feature2', 'feature3', 'feature4', 'feature5']].mean(axis=1)
        df['feature_std'] = df[['feature1', 'feature2', 'feature3', 'feature4', 'feature5']].std(axis=1)
        df['feature_max'] = df[['feature1', 'feature2', 'feature3', 'feature4', 'feature5']].max(axis=1)
        st.success("çµ±è¨ˆç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    if st.checkbox("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"):
        le = LabelEncoder()
        df['category_encoded'] = le.fit_transform(df['category'])
        st.success("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
    
    # ç‰¹å¾´é‡é¸æŠ
    st.subheader("ğŸ¯ ç‰¹å¾´é‡é¸æŠ")
    
    # æ•°å€¤ç‰¹å¾´é‡ã®ã¿é¸æŠ
    numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
    if 'target' in numeric_features:
        numeric_features.remove('target')
    
    selected_features = st.multiselect(
        "ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ",
        numeric_features,
        default=numeric_features
    )
    
    if selected_features:
        X = df[selected_features]
        y = df['target']
        
        # ç›¸é–¢åˆ†æ
        st.subheader("ğŸ“Š ç‰¹å¾´é‡ç›¸é–¢åˆ†æ")
        
        correlation_matrix = X.corr()
        fig_corr = px.imshow(
            correlation_matrix,
            title="ç‰¹å¾´é‡ç›¸é–¢è¡Œåˆ—",
            color_continuous_scale='RdBu',
            aspect='auto'
        )
        st.plotly_chart(fig_corr, use_container_width=True)
        
        # PCAåˆ†æ
        st.subheader("ğŸ“‰ PCAåˆ†æ")
        
        n_components = st.slider("ä¸»æˆåˆ†æ•°", 2, min(len(selected_features), 10), 3)
        
        if st.button("PCAå®Ÿè¡Œ"):
            with st.spinner("PCAå®Ÿè¡Œä¸­..."):
                pca = PCA(n_components=n_components)
                X_pca = pca.fit_transform(X)
                
                # èª¬æ˜åˆ†æ•£æ¯”
                explained_variance_ratio = pca.explained_variance_ratio_
                cumulative_variance_ratio = np.cumsum(explained_variance_ratio)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    fig_variance = px.bar(
                        x=list(range(1, n_components + 1)),
                        y=explained_variance_ratio,
                        title="å„ä¸»æˆåˆ†ã®èª¬æ˜åˆ†æ•£æ¯”"
                    )
                    st.plotly_chart(fig_variance, use_container_width=True)
                
                with col2:
                    fig_cumulative = px.line(
                        x=list(range(1, n_components + 1)),
                        y=cumulative_variance_ratio,
                        title="ç´¯ç©èª¬æ˜åˆ†æ•£æ¯”"
                    )
                    st.plotly_chart(fig_cumulative, use_container_width=True)
                
                # PCAçµæœã®å¯è¦–åŒ–
                if n_components >= 2:
                    pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(n_components)])
                    pca_df['target'] = y
                    
                    fig_pca = px.scatter(
                        pca_df,
                        x='PC1',
                        y='PC2',
                        color='target',
                        title="PCAçµæœï¼ˆPC1 vs PC2ï¼‰"
                    )
                    st.plotly_chart(fig_pca, use_container_width=True)
                
                # ç‰¹å¾´é‡ã®å¯„ä¸åº¦
                feature_importance = pd.DataFrame({
                    'feature': selected_features,
                    'PC1_contribution': np.abs(pca.components_[0]),
                    'PC2_contribution': np.abs(pca.components_[1]) if n_components > 1 else 0
                })
                
                st.subheader("ğŸ¯ ç‰¹å¾´é‡ã®ä¸»æˆåˆ†ã¸ã®å¯„ä¸åº¦")
                st.dataframe(feature_importance, use_container_width=True)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ³ãƒ | Streamlit 1.46.1 | 2025å¹´7æœˆ1æ—¥</p>
</div>
""", unsafe_allow_html=True) 