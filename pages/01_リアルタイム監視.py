import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from datetime import datetime, timedelta
import random

st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–",
    page_icon="ğŸ“¡",
    layout="wide"
)

st.title("ğŸ“¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
@st.cache_data
def generate_realtime_data():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    np.random.seed(42)
    
    # ç¾åœ¨æ™‚åˆ»ã‹ã‚‰éå»24æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿
    end_time = datetime.now()
    start_time = end_time - timedelta(hours=24)
    
    timestamps = pd.date_range(start=start_time, end=end_time, freq='1min')
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    cpu_usage = []
    memory_usage = []
    network_traffic = []
    active_users = []
    error_rate = []
    
    for i, timestamp in enumerate(timestamps):
        # CPUä½¿ç”¨ç‡ï¼ˆæ™‚é–“å¸¯ã«ã‚ˆã‚‹å¤‰å‹•ï¼‰
        hour = timestamp.hour
        base_cpu = 30 + 20 * np.sin(2 * np.pi * hour / 24)
        cpu = base_cpu + np.random.normal(0, 5)
        cpu_usage.append(max(0, min(100, cpu)))
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
        memory = 60 + np.random.normal(0, 10)
        memory_usage.append(max(0, min(100, memory)))
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
        base_traffic = 100 + 50 * np.sin(2 * np.pi * hour / 24)
        traffic = base_traffic + np.random.normal(0, 20)
        network_traffic.append(max(0, traffic))
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
        base_users = 50 + 30 * np.sin(2 * np.pi * hour / 24)
        users = base_users + np.random.poisson(10)
        active_users.append(max(0, users))
        
        # ã‚¨ãƒ©ãƒ¼ç‡
        base_error = 0.5 + 0.3 * np.sin(2 * np.pi * hour / 24)
        error = base_error + np.random.exponential(0.1)
        error_rate.append(max(0, min(5, error)))
    
    return pd.DataFrame({
        'timestamp': timestamps,
        'cpu_usage': cpu_usage,
        'memory_usage': memory_usage,
        'network_traffic': network_traffic,
        'active_users': active_users,
        'error_rate': error_rate
    })

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
data = generate_realtime_data()

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®è¨­å®š
if 'last_update' not in st.session_state:
    st.session_state.last_update = datetime.now()

# è‡ªå‹•æ›´æ–°ã®è¨­å®š
auto_refresh = st.sidebar.checkbox("ğŸ”„ è‡ªå‹•æ›´æ–°", value=False)
refresh_interval = st.sidebar.slider("æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰", 1, 60, 5)

if auto_refresh:
    time.sleep(refresh_interval)
    st.rerun()

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
st.sidebar.markdown("### ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š")
cpu_threshold = st.sidebar.slider("CPUä½¿ç”¨ç‡é–¾å€¤ (%)", 50, 95, 80)
memory_threshold = st.sidebar.slider("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡é–¾å€¤ (%)", 50, 95, 85)
error_threshold = st.sidebar.slider("ã‚¨ãƒ©ãƒ¼ç‡é–¾å€¤ (%)", 0.1, 5.0, 2.0)

# ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
st.subheader("ğŸ–¥ï¸ ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")

col1, col2, col3, col4 = st.columns(4)

with col1:
    current_cpu = data['cpu_usage'].iloc[-1]
    cpu_color = "red" if current_cpu > cpu_threshold else "green"
    st.metric(
        "CPUä½¿ç”¨ç‡", 
        f"{current_cpu:.1f}%",
        delta=f"{data['cpu_usage'].iloc[-1] - data['cpu_usage'].iloc[-2]:.1f}%"
    )

with col2:
    current_memory = data['memory_usage'].iloc[-1]
    memory_color = "red" if current_memory > memory_threshold else "green"
    st.metric(
        "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", 
        f"{current_memory:.1f}%",
        delta=f"{data['memory_usage'].iloc[-1] - data['memory_usage'].iloc[-2]:.1f}%"
    )

with col3:
    current_traffic = data['network_traffic'].iloc[-1]
    st.metric(
        "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯", 
        f"{current_traffic:.0f} Mbps",
        delta=f"{data['network_traffic'].iloc[-1] - data['network_traffic'].iloc[-2]:.0f} Mbps"
    )

with col4:
    current_users = data['active_users'].iloc[-1]
    st.metric(
        "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼", 
        f"{current_users:.0f}äºº",
        delta=f"{data['active_users'].iloc[-1] - data['active_users'].iloc[-2]:.0f}äºº"
    )

# ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
st.subheader("ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ")

alerts = []
if current_cpu > cpu_threshold:
    alerts.append(f"âš ï¸ CPUä½¿ç”¨ç‡ãŒé–¾å€¤ï¼ˆ{cpu_threshold}%ï¼‰ã‚’è¶…é: {current_cpu:.1f}%")

if current_memory > memory_threshold:
    alerts.append(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé–¾å€¤ï¼ˆ{memory_threshold}%ï¼‰ã‚’è¶…é: {current_memory:.1f}%")

if data['error_rate'].iloc[-1] > error_threshold:
    alerts.append(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ç‡ãŒé–¾å€¤ï¼ˆ{error_threshold}%ï¼‰ã‚’è¶…é: {data['error_rate'].iloc[-1]:.2f}%")

if alerts:
    for alert in alerts:
        st.error(alert)
else:
    st.success("âœ… ã™ã¹ã¦ã®ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ãƒˆ
st.subheader("ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹")

# ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('CPUä½¿ç”¨ç‡', 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯', 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼'),
    specs=[[{"secondary_y": False}, {"secondary_y": False}],
           [{"secondary_y": False}, {"secondary_y": False}]]
)

# CPUä½¿ç”¨ç‡
fig.add_trace(
    go.Scatter(
        x=data['timestamp'],
        y=data['cpu_usage'],
        mode='lines',
        name='CPUä½¿ç”¨ç‡',
        line=dict(color='red', width=2)
    ),
    row=1, col=1
)

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
fig.add_trace(
    go.Scatter(
        x=data['timestamp'],
        y=data['memory_usage'],
        mode='lines',
        name='ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡',
        line=dict(color='blue', width=2)
    ),
    row=1, col=2
)

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
fig.add_trace(
    go.Scatter(
        x=data['timestamp'],
        y=data['network_traffic'],
        mode='lines',
        name='ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯',
        line=dict(color='green', width=2)
    ),
    row=2, col=1
)

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼
fig.add_trace(
    go.Scatter(
        x=data['timestamp'],
        y=data['active_users'],
        mode='lines',
        name='ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼',
        line=dict(color='purple', width=2)
    ),
    row=2, col=2
)

# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®æ›´æ–°
fig.update_layout(
    height=600,
    showlegend=False,
    title_text="24æ™‚é–“ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹"
)

# é–¾å€¤ãƒ©ã‚¤ãƒ³ã®è¿½åŠ 
for i in range(1, 3):
    for j in range(1, 3):
        if i == 1 and j == 1:  # CPUä½¿ç”¨ç‡
            fig.add_hline(y=cpu_threshold, line_dash="dash", line_color="red", 
                         annotation_text=f"é–¾å€¤: {cpu_threshold}%", row=i, col=j)
        elif i == 1 and j == 2:  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            fig.add_hline(y=memory_threshold, line_dash="dash", line_color="red", 
                         annotation_text=f"é–¾å€¤: {memory_threshold}%", row=i, col=j)

st.plotly_chart(fig, use_container_width=True)

# ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°
st.subheader("ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°")

# ãƒ¢ãƒƒã‚¯ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
log_entries = [
    {"timestamp": datetime.now() - timedelta(minutes=5), "level": "INFO", "message": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæ­£å¸¸ã«ç¢ºç«‹ã•ã‚Œã¾ã—ãŸ"},
    {"timestamp": datetime.now() - timedelta(minutes=4), "level": "WARNING", "message": "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒ70%ã‚’è¶…éã—ã¾ã—ãŸ"},
    {"timestamp": datetime.now() - timedelta(minutes=3), "level": "INFO", "message": "æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ"},
    {"timestamp": datetime.now() - timedelta(minutes=2), "level": "ERROR", "message": "APIå‘¼ã³å‡ºã—ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸ"},
    {"timestamp": datetime.now() - timedelta(minutes=1), "level": "INFO", "message": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"},
    {"timestamp": datetime.now(), "level": "INFO", "message": "ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™"}
]

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
log_level = st.selectbox("ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°", ["ã™ã¹ã¦", "INFO", "WARNING", "ERROR"])

filtered_logs = log_entries
if log_level != "ã™ã¹ã¦":
    filtered_logs = [log for log in log_entries if log["level"] == log_level]

# ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤º
log_df = pd.DataFrame(filtered_logs)
if not log_df.empty:
    for _, log in log_df.iterrows():
        if log["level"] == "ERROR":
            st.error(f"{log['timestamp'].strftime('%H:%M:%S')} - {log['level']}: {log['message']}")
        elif log["level"] == "WARNING":
            st.warning(f"{log['timestamp'].strftime('%H:%M:%S')} - {log['level']}: {log['message']}")
        else:
            st.info(f"{log['timestamp'].strftime('%H:%M:%S')} - {log['level']}: {log['message']}")

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
st.subheader("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")

col1, col2, col3 = st.columns(3)

with col1:
    st.metric("å¹³å‡CPUä½¿ç”¨ç‡", f"{data['cpu_usage'].mean():.1f}%")
    st.metric("æœ€å¤§CPUä½¿ç”¨ç‡", f"{data['cpu_usage'].max():.1f}%")

with col2:
    st.metric("å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{data['memory_usage'].mean():.1f}%")
    st.metric("æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{data['memory_usage'].max():.1f}%")

with col3:
    st.metric("å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡", f"{data['error_rate'].mean():.2f}%")
    st.metric("æœ€å¤§ã‚¨ãƒ©ãƒ¼ç‡", f"{data['error_rate'].max():.2f}%")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸ“¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ | æœ€çµ‚æ›´æ–°: {}</p>
</div>
""".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')), unsafe_allow_html=True) 