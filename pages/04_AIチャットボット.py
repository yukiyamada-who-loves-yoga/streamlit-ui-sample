import streamlit as st
import openai
from datetime import datetime
import json

st.set_page_config(
    page_title="AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = ""

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.markdown("### âš™ï¸ è¨­å®š")

# APIã‚­ãƒ¼å…¥åŠ›
api_key = st.sidebar.text_input(
    "OpenAI APIã‚­ãƒ¼",
    type="password",
    help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå¿…é ˆï¼‰",
    value=st.session_state.openai_api_key
)

if api_key != st.session_state.openai_api_key:
    st.session_state.openai_api_key = api_key
    st.session_state.chat_history = []
    st.rerun()

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
model = st.sidebar.selectbox(
    "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
    ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
    index=0,
    help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
)

# æ¸©åº¦è¨­å®š
temperature = st.sidebar.slider(
    "å‰µé€ æ€§ï¼ˆæ¸©åº¦ï¼‰",
    min_value=0.0,
    max_value=2.0,
    value=0.7,
    step=0.1,
    help="å€¤ãŒé«˜ã„ã»ã©å‰µé€ çš„ãªå›ç­”ã«ãªã‚Šã¾ã™"
)

# æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
max_tokens = st.sidebar.slider(
    "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
    min_value=100,
    max_value=4000,
    value=1000,
    step=100,
    help="å›ç­”ã®æœ€å¤§é•·ã‚’è¨­å®šã—ã¾ã™"
)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
    st.session_state.chat_history = []
    st.rerun()

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not api_key:
    st.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.info("""
    ### ä½¿ç”¨æ–¹æ³•
    1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›
    2. ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
    3. ãƒãƒ£ãƒƒãƒˆãƒœãƒƒã‚¯ã‚¹ã«è³ªå•ã‚’å…¥åŠ›
    4. AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨å¯¾è©±ã‚’é–‹å§‹
    
    ### å¯¾å¿œæ©Ÿèƒ½
    - ä¸€èˆ¬çš„ãªè³ªå•ã¸ã®å›ç­”
    - ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ã‚µãƒãƒ¼ãƒˆ
    - ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    - ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥ã®ææ¡ˆ
    - å­¦ç¿’æ”¯æ´
    """)
else:
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    st.markdown("### ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
        user_message = {
            "role": "user",
            "content": prompt,
            "timestamp": datetime.now().isoformat()
        }
        st.session_state.chat_history.append(user_message)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AIå¿œç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤– AIãŒè€ƒãˆä¸­..."):
                try:
                    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
                    client = openai.OpenAI(api_key=api_key)
                    
                    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®š
                    system_prompt = """ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š

1. æ—¥æœ¬èªã§ä¸å¯§ã«å›ç­”ã™ã‚‹
2. è³ªå•è€…ã®ãƒ¬ãƒ™ãƒ«ã«åˆã‚ã›ã¦èª¬æ˜ã™ã‚‹
3. å¿…è¦ã«å¿œã˜ã¦å…·ä½“ä¾‹ã‚’æŒ™ã’ã‚‹
4. ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚„ãƒ‡ãƒ¼ã‚¿åˆ†æã®è³ªå•ã«ã¯å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹
5. ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã®è³ªå•ã«ã¯æˆ¦ç•¥çš„ãªè¦–ç‚¹ã§å›ç­”ã™ã‚‹
6. å­¦ç¿’æ”¯æ´ã§ã¯æ®µéšçš„ãªèª¬æ˜ã‚’å¿ƒãŒã‘ã‚‹
7. ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°è³ªå•ã—ã¦æ˜ç¢ºã«ã™ã‚‹

å¸¸ã«å»ºè¨­çš„ã§å½¹ç«‹ã¤å›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®æº–å‚™
                    messages = [{"role": "system", "content": system_prompt}]
                    
                    # éå»ã®ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€æ–°ã®10ä»¶ã¾ã§ï¼‰
                    recent_history = st.session_state.chat_history[-10:]
                    for msg in recent_history:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
                    
                    # OpenAI APIã‚’å‘¼ã³å‡ºã—
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        temperature=temperature,
                        max_tokens=max_tokens
                    )
                    
                    # AIå¿œç­”ã‚’å–å¾—
                    ai_response = response.choices[0].message.content
                    
                    # AIå¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                    ai_message = {
                        "role": "assistant",
                        "content": ai_response,
                        "timestamp": datetime.now().isoformat()
                    }
                    st.session_state.chat_history.append(ai_message)
                    
                    # AIå¿œç­”ã‚’è¡¨ç¤º
                    st.markdown(ai_response)
                    
                except openai.AuthenticationError:
                    st.error("âŒ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚æ­£ã—ã„APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                except openai.RateLimitError:
                    st.error("âŒ APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                except openai.APIError as e:
                    st.error(f"âŒ APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                except Exception as e:
                    st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®çµ±è¨ˆæƒ…å ±
    if st.session_state.chat_history:
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            user_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "user"])
            st.metric("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", user_messages)
        
        with col2:
            ai_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "assistant"])
            st.metric("AIå¿œç­”æ•°", ai_messages)
        
        with col3:
            total_messages = len(st.session_state.chat_history)
            st.metric("ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", total_messages)
    
    # ã‚ˆãã‚ã‚‹è³ªå•ã®ä¾‹
    st.markdown("---")
    st.markdown("### ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•ã®ä¾‹")
    
    example_questions = [
        "Pythonã§ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å§‹ã‚ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ",
        "Streamlitã‚¢ãƒ—ãƒªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„",
        "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã‚³ãƒ„ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã§åŠ¹æœçš„ãªã‚°ãƒ©ãƒ•ã®é¸ã³æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æ•™ãˆã¦ãã ã•ã„"
    ]
    
    cols = st.columns(len(example_questions))
    for i, question in enumerate(example_questions):
        with cols[i]:
            if st.button(f"ä¾‹{i+1}", key=f"example_{i}"):
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": question,
                    "timestamp": datetime.now().isoformat()
                })
                st.rerun()

# ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.8em;'>
    <p>ğŸ¤– AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ - è³ªå•ã‚„ç–‘å•ã‚’æ°—è»½ã«ç›¸è«‡ã—ã¦ãã ã•ã„</p>
    <p>Powered by OpenAI GPT Models | Streamlit 1.46.1</p>
</div>
""", unsafe_allow_html=True) 